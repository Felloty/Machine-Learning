{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLKQNyiVt-nR"
   },
   "source": [
    "## Многомерная линейная регрессия из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Pa-Lia6St-nR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rCVSClXut-nS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples = 10000)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m41sLfcJt-nS"
   },
   "source": [
    "У нас 10000 объектов и 100 признаков. Для начала решим задачу аналитически \"из коробки\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Xx3P6hOVt-nS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.619957835812702e-25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 9.68230640e-14, -3.33066907e-14,  8.08242362e-14,  3.73034936e-14,\n",
       "        3.33376241e+00,  5.62160448e+01, -7.06101844e-14, -1.77635684e-15,\n",
       "       -8.52651283e-14, -2.64233080e-14,  3.28626015e-14,  3.28626015e-14,\n",
       "        1.06581410e-14, -2.62567745e-14,  7.28306304e-14, -7.10542736e-15,\n",
       "        8.61113405e+01, -5.32907052e-15, -4.79616347e-14,  6.08402217e-14,\n",
       "        2.48689958e-14,  1.77635684e-14,  3.55271368e-14,  9.23705556e-14,\n",
       "        2.13162821e-14, -1.24344979e-14, -3.90798505e-14, -3.55271368e-15,\n",
       "        3.01980663e-14,  3.41948692e-14,  2.84217094e-14,  6.03961325e-14,\n",
       "        2.27345007e+01,  3.78803227e+01, -2.08721929e-14, -6.26165786e-14,\n",
       "       -3.06421555e-14, -9.99200722e-14,  5.41788836e-14, -9.76996262e-14,\n",
       "        1.87981903e+01, -3.55271368e-14,  4.70734562e-14, -6.75015599e-14,\n",
       "       -9.59787805e-14,  2.48689958e-14, -2.55351296e-15, -1.03916875e-13,\n",
       "       -6.57252031e-14,  2.66453526e-15,  1.90958360e-14, -3.46389584e-14,\n",
       "        6.48370246e-14, -1.90958360e-14,  1.11022302e-15,  8.06355285e+01,\n",
       "       -1.15463195e-14, -4.61852778e-14,  1.77635684e-14,  2.04281037e-14,\n",
       "       -1.33226763e-14,  1.25455202e-13, -2.39808173e-14, -8.88178420e-14,\n",
       "       -1.77635684e-14,  6.21724894e-15, -6.75015599e-14, -6.21724894e-15,\n",
       "        2.13162821e-14,  5.95079541e-14,  4.79616347e-14, -8.97060204e-14,\n",
       "        5.68434189e-14, -2.57571742e-14, -2.04281037e-14,  3.12985495e+01,\n",
       "       -3.90798505e-14, -1.42108547e-14, -2.57571742e-14, -2.57571742e-14,\n",
       "        3.55271368e-15, -7.37188088e-14,  8.87052112e+01, -7.86037901e-14,\n",
       "       -2.13162821e-14,  3.01980663e-14, -5.28466160e-14,  4.61852778e-14,\n",
       "        8.55347041e+01, -4.44089210e-15,  2.66453526e-14, -5.86197757e-14,\n",
       "       -8.88178420e-16,  6.03961325e-14, -1.77635684e-15, -3.55271368e-14,\n",
       "        4.79616347e-14,  4.88498131e-15,  2.48689958e-14,  1.06581410e-14])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X, y)\n",
    "print(mean_squared_error(y, reg.predict(X)))\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNWLYeKst-nS"
   },
   "source": [
    "Теперь попробуем обучить линейную регрессию методом градиентного спуска \"из коробки\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hK5BO3uxt-nS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.553264604811319e-12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.06854691e-09, -4.18181583e-08,  5.52675653e-08,  5.32867269e-08,\n",
       "        3.33376240e+00,  5.62160442e+01,  5.54449968e-08,  2.87677552e-08,\n",
       "       -8.05639500e-09,  2.42660106e-08,  1.10837187e-08,  5.18185751e-09,\n",
       "       -2.59473592e-08, -2.89735827e-08, -5.07963256e-08,  2.68112184e-08,\n",
       "        8.61113397e+01, -4.22635242e-08, -1.16558140e-08,  1.59535467e-08,\n",
       "        2.68941502e-09, -1.79630199e-08, -3.91794477e-08, -2.59475180e-08,\n",
       "        5.38865128e-08, -1.31258742e-08,  2.33222267e-08,  8.82733917e-09,\n",
       "        3.63348244e-09, -1.39049607e-10, -1.18080098e-08, -2.37316202e-08,\n",
       "        2.27345005e+01,  3.78803223e+01,  4.82476003e-08,  3.08507763e-08,\n",
       "       -1.56813385e-08, -2.11890394e-08, -4.73571270e-08,  2.07121286e-08,\n",
       "        1.87981901e+01,  4.76543008e-08, -7.20627781e-08,  1.52830819e-08,\n",
       "       -4.90817013e-08, -2.18510911e-08, -2.46117346e-08, -1.05446329e-07,\n",
       "        2.45665989e-08, -3.08284821e-08, -4.65110322e-08, -9.88177290e-09,\n",
       "        3.72029066e-09,  9.48666663e-09,  1.60262099e-08,  8.06355277e+01,\n",
       "        3.79454669e-08,  1.32651891e-08, -1.42632045e-08, -2.50596477e-08,\n",
       "        3.96971981e-08,  1.16556917e-08, -5.02136150e-08, -2.80395583e-08,\n",
       "       -2.49103829e-09, -4.45715288e-09,  3.95836612e-08, -4.68350490e-08,\n",
       "       -8.39006581e-09,  5.12130306e-08, -6.17959947e-09,  1.88229296e-08,\n",
       "       -3.86928810e-08,  3.35089697e-09,  1.37946603e-08,  3.12985492e+01,\n",
       "       -7.66634463e-09,  4.41054500e-08,  3.57310613e-09, -8.21028295e-09,\n",
       "        3.05381754e-08, -5.32902325e-08,  8.87052103e+01,  8.58707225e-09,\n",
       "        1.15881540e-08,  5.86145661e-08, -9.43190185e-09, -5.31264086e-09,\n",
       "        8.55347033e+01,  2.84290398e-08,  2.15850892e-09, -1.05574887e-08,\n",
       "        4.67841669e-08, -8.28877743e-09,  1.26582011e-10, -1.65376297e-08,\n",
       "        9.51073260e-09, -1.08399532e-08,  2.98335740e-08,  8.71382900e-08])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = SGDRegressor(alpha = 0.00000001).fit(X, y)\n",
    "print(mean_squared_error(y, reg.predict(X)))\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MCjcHrSt-nS"
   },
   "source": [
    "***Задание 1 (0.5 балла).*** Объясните, чем вызвано различие двух полученных значений метрики?\n",
    "\n",
    "Различие двух полученных значений метрики вызвано различием способов минимизации функции потерь и их гиперпараметрами. В случае LinearRegression скорее всего используется стандартный или модифицированный SVD-метод, в случае же с SGDRegressor SGD-метод. Конкретно же данное различие вызвано наличием в SGDRegressor по умолчанию включённой l2-регуляризации с указанным параметром alpha. Его можно установить равным нулю для того, чтобы значение MSE было близко к значению MSE, полученному при обучении LinearRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Задание 2 (0.5 балла).*** Подберите гиперпараметры в методе градиентного спуска так, чтобы значение MSE было близко к значению MSE, полученному при обучении LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.541996130079201e-25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.00689848e-14, -4.18774170e-15,  5.42208616e-15,  3.64788917e-15,\n",
       "        3.33376241e+00,  5.62160448e+01,  1.32064198e-14,  1.69346207e-14,\n",
       "       -4.83131763e-14, -6.78597331e-15, -1.27959255e-14,  1.32792030e-14,\n",
       "        9.22536480e-15, -6.87486875e-15,  1.08551963e-14,  2.17523129e-14,\n",
       "        8.61113405e+01,  1.13219812e-14,  5.87039218e-15,  1.33939107e-14,\n",
       "       -1.35147201e-14, -1.00187838e-14, -5.26272728e-15, -5.39412541e-15,\n",
       "       -9.95001878e-16, -1.26063004e-14, -1.61251088e-14, -1.19440460e-15,\n",
       "        1.17541617e-14, -1.02653644e-15, -1.85152282e-14,  1.14743711e-15,\n",
       "        2.27345007e+01,  3.78803227e+01, -8.58898998e-15, -6.21808017e-15,\n",
       "       -7.39413435e-15, -4.29333338e-15, -1.85299710e-14, -2.38998504e-14,\n",
       "        1.87981903e+01,  1.88089974e-14, -2.28134157e-14,  3.07668434e-15,\n",
       "       -2.48103559e-14, -1.99816769e-16,  1.36927840e-14,  1.09584870e-14,\n",
       "        8.39406108e-15, -1.18828255e-14,  1.64287272e-14, -1.93415136e-16,\n",
       "       -2.59796225e-14, -1.63629447e-14, -2.86724325e-16,  8.06355285e+01,\n",
       "       -7.09121677e-15,  2.19676091e-15, -3.67701982e-14,  4.28326959e-15,\n",
       "        4.06489069e-15,  2.82208348e-14, -1.93649990e-15, -7.92720837e-15,\n",
       "        4.18591191e-15,  1.43724505e-15, -2.29368220e-15, -7.47966921e-15,\n",
       "       -1.93441027e-14,  2.49785647e-15, -2.61077583e-15, -2.01143475e-14,\n",
       "        5.34144497e-15,  1.41438145e-15,  7.13236323e-15,  3.12985495e+01,\n",
       "        3.57555463e-14,  2.24461715e-14,  7.41324381e-15,  1.64931532e-14,\n",
       "       -3.71097658e-14, -1.17259771e-14,  8.87052112e+01, -8.83932093e-15,\n",
       "        1.38187408e-15,  1.47568410e-14, -1.29655507e-14,  1.30359615e-14,\n",
       "        8.55347041e+01, -1.42491346e-14, -1.02804852e-14, -7.68143839e-15,\n",
       "        1.21165754e-15, -7.14459484e-15,  1.57481584e-14, -1.59748461e-14,\n",
       "       -3.18956512e-14, -2.23064031e-14,  3.58718209e-15,  1.02881383e-14])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = SGDRegressor(alpha = 0.0).fit(X, y)\n",
    "print(mean_squared_error(y, reg.predict(X)))\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xG7V0qzut-nT"
   },
   "source": [
    "## Моя многомерная линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Задание 3 (5 баллов)***. Напишите собственную многомерную линейную регрессию, оптимизирующую MSE методом *градиентного спуска*. Для этого используйте шаблонный класс.\n",
    "\n",
    "Критерий останова: либо норма разности весов на текущей и предыдущей итерациях меньше определенного значения (первый и третий варианты), либо модуль разности функционалов качества (MSE) на текущей и предыдущей итерациях меньше определенного значения (второй и четвертый варианты). Также предлагается завершать обучение в любом случае, если было произведено слишком много итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(object):\n",
    "    def __init__(self, alpha = 0.0001, tol = 0.001, max_iter = 1000):\n",
    "        self.a = alpha\n",
    "        self.e = tol\n",
    "        self.n = max_iter\n",
    "\n",
    "    def fit(self, X, y): # Будем использовать векторную форму\n",
    "\n",
    "        features = np.c_[X, np.ones(len(X))] # Добавляем столбец с единицами к матрице признаков\n",
    "        weights = np.ones(features.shape[1]) # Инициализируем вектор подбираемых весов\n",
    "        diff_mse = 1\n",
    "        steps = 0\n",
    "        mse = 1\n",
    "\n",
    "        while(diff_mse >= self.e):\n",
    "\n",
    "            if steps > self.n:\n",
    "                break\n",
    "\n",
    "            y_pred = features @ weights.T # Вычисляем вектор прогнозируемых значений\n",
    "            grad = features.T @ (y - y_pred) # Вычисляем вектор частных производных (градиент)\n",
    "\n",
    "            diff_mse = np.abs((np.sum(np.square(y - y_pred)) / float(len(y))) - mse) # Вычисляем модуль разности MSE\n",
    "            weights = weights.T + (self.a * grad) # Вычисляем вектор обновленных весов\n",
    "\n",
    "            if (np.isnan(np.sum(np.sqrt(np.square(grad))))):\n",
    "                warnings.warn('The model diverged, too big learning rate!')\n",
    "\n",
    "            mse = np.sum(np.square(y - y_pred)) / float(len(y))\n",
    "            steps = steps + 1\n",
    "\n",
    "        return weights\n",
    "\n",
    "    def predict(self, X, weights):\n",
    "        return weights[:-1] @ np.array(X).T + weights[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9224653340578444e-07\n"
     ]
    }
   ],
   "source": [
    "my_reg = LinearRegression()\n",
    "print(mean_squared_error(y, my_reg.predict(X, my_reg.fit(X, y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-LvqfXkt-nT"
   },
   "source": [
    "***Задание 5 (1 балл)***. Обучите линейную регрессию из коробки\n",
    "\n",
    "* с l1-регуляризацией (from sklearn.linear_model import Lasso)\n",
    "* со значением параметра регуляризации 0.1\n",
    "\n",
    "Обучите вашу линейную регрессию с тем же значением параметра регуляризации и сравните результаты. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vXFGXaAwt-nT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09870757639434172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.        , -0.        ,  0.        ,  3.23561289,\n",
       "       56.12141802, -0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        , 86.01139093, -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        , 22.63568343, 37.78135689,  0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "       18.70342382,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "       80.53455096, -0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       31.20100196,  0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        , 88.605075  ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , 85.43123344,  0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = Lasso(alpha = 0.1).fit(X, y)\n",
    "print(mean_squared_error(y, reg.predict(X)))\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
